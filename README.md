# ğŸ¤– SHOP ASSIST RAG Chatbot (LangChain + FAISS + Ollama)

A **production-style local AI chatbot** that allows users to chat with **PDF/TXT documents** using **RAG (Retrieval-Augmented Generation)** â€” without using any paid APIs.

This project is built like real-world support chatbots (Amazon / Flipkart style), where answers come from internal documents such as:

âœ… Policies  
âœ… Orders / returns  
âœ… FAQs  
âœ… Product manuals  
âœ… Knowledge base PDFs  

---
# USER
<img width="1920" height="1080" alt="Screenshot (298)" src="https://github.com/user-attachments/assets/e992eb1b-c731-44ae-ad7f-1fee1802c32f" />

---
# ADMIN
<img width="1920" height="1080" alt="Screenshot (299)" src="https://github.com/user-attachments/assets/26cfdb07-619e-4634-a3ee-5f8a92fa26f6" />

---
## ğŸš€ Project Motto

**"Make AI chatbots private, local, and document-grounded â€” with real-world deployment features."**

---

## ğŸ“Œ What This Project Does

This chatbot provides:

### ğŸ‘¤ Users
- Login and ask questions from uploaded documents
- Get answers based only on company PDFs
- Chat continuously with conversation memory

### ğŸ‘¨â€ğŸ’¼ Admin
- Upload multiple PDFs/TXT files
- Build & update FAISS index
- Save index locally (no need to upload again)
- Enable Developer Mode (evidence + score + debug)

---

## ğŸ”¥ Key Features

### âœ… 1. Fully Local (No OpenAI API Needed)
- Runs on your laptop using **Ollama**
- Works offline after models + index are ready

### âœ… 2. Multi-file Upload (Admin Only)
- Admin can upload multiple PDFs/TXTs together
- All documents are added into one FAISS index

### âœ… 3. Saved FAISS Index
- Index is stored locally in `faiss_index/`
- Next time app runs, it loads automatically

### âœ… 4. Strict Mode (Document-only Answers)
- When enabled, chatbot answers only from document context
- If context is missing â†’ responds:
  > "I don't know based on the document."

### âœ… 5. Admin/User Authentication (Roles)
- Admin can manage index
- Users can only chat

### âœ… 6. Conversation Memory Per Document Index
- Chat memory is stored per FAISS index
- Helps follow-up questions and continuity

### âœ… 7. Developer Mode (Admin only)
Developer mode shows:

- Retrieved chunks
- Evidence
- Groundedness score
- Source file + page number

In production, this is hidden from users.

---

## ğŸ§  Tech Stack

| Component | Tool |
|----------|------|
| Frontend UI | Streamlit |
| LLM | Ollama (Qwen2.5:3B) |
| Embeddings | nomic-embed-text |
| Vector DB | FAISS |
| RAG Framework | LangChain |
| Language | Python |

---

## ğŸ—ï¸ Architecture (High Level)
<img width="1536" height="1024" alt="ChatGPT Image Feb 9, 2026, 08_27_19 PM" src="https://github.com/user-attachments/assets/26663bad-32fd-4713-9e84-ede3c7e06077" />

1. Admin uploads PDFs/TXTs  
2. Documents are split into chunks  
3. Chunks are converted into embeddings  
4. FAISS stores embeddings for fast retrieval  
5. User asks a question  
6. Retriever fetches top chunks  
7. LLM generates answer using retrieved context  
8. Response is shown in chat UI  

---

## ğŸ“‚ Folder Structure

```bash
rag-chatbot/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ users.json
â”œâ”€â”€ faiss_index/           # auto created after indexing
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ loader.py
â”‚   â”œâ”€â”€ vectorstore.py
â”‚   â”œâ”€â”€ rag_chain.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


